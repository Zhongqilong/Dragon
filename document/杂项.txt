Forward
在Forward渲染路径下，每个物体会被每个光源渲染成一个“通道”，因此物体受到越多灯光的影响，其渲染次数就会越多。
Forward渲染路径的优势在于，在灯光比较少的情况下，Forward方式的渲染速度会非常快，处理透明贴图也非常快，还可以使用诸如“多重取样抗锯齿（MSAA）”这样的硬件处理技术技术。
但Forward渲染路径的渲染速度会随着灯光的增多而迅速变慢，在一些有很多灯光照明的特定场景中（比如高科技室内环境）并不适合使用Forward渲染路径。

Deferred
使用Deffered渲染路径，渲染时间不会随着灯光的增多而提高，而是会随着受整体光照影响区域的扩大而提高（也就是说，场景中越多像素被照亮，渲染速度就越慢，但全屏被照亮的情况下，灯光设置复杂度不会进一步影响渲染速度了）。
Deffered渲染路径在整体上需要更多的计算量，对于一些移动设备，Deffered渲染路径还不能支持。
新版Unity3D的默认渲染路径是Deffered渲染，如果场景非常简单，或者希望使用MSAA，可以自行修改成Forward渲染路径。

使用反射探针（Reflection Probe）
Unity3D中并没并真实的Raytrace反射，而是通过反射贴图来模拟所有的反射效果。
如果我们在场景中放置一个非常强反射的小球，我们就能看到这个小球上实际反射的是我们的Skybox，完全不会反射场景物体。这样一来不仅影响到场景中反光物体的反射正确性，同时也会严重影响整体场景的光照准确性。
我们可以为场景添加Reflection Probe来矫正不正确的反射贴图。
Reflection Probe可以看做是一个带有6个摄影机的点，它会渲染该点的6个方向（前后左右上下），将渲染结果拼成一个Cubemap，并应用给一个特定方框范围内的所有物体作为反射贴图。
对于比较复杂的环境，比如有多个区域的大房间，我们可以放置多个Reflection Probe并手动设置其影响范围。
Reflection Probe默认不会计算动态物体，仅计算烘焙物体，我们可以修改属性让其将动态物体也包括在内，同时还可以修改属性为Every Frame使其每帧更新以准确反射动态物体的运动过程，还可以增加Lighting Setting中的Reflection Bounces提高反射次数（这样就不会出现强反射物体在另一个反射物体中是黑色的情况了）。但要注意，这些修改都会占用更多的系统资源，尤其是每帧更新反射贴图这样的设置。

如何提高烘焙效率
烘焙效率虽然不影响最终游戏的表现，但对我们制作过程有很大的影响。没人会希望每次修改了场景布局或者灯光布局之后都要花费几个小时甚至几十个小时的时间来烘焙光照贴图。
一个小技巧是不要将所有物体都设置成Lightmap Static参与光照贴图的烘焙。很多细碎的物体（比如地上的小碎石）并不需要很精确的间接光照效果，而且也可能根本没有足够的光照贴图精度来对应这些细碎物体，这时候用灯光探针可能比用光照贴图更有效率。
在Unite 2017关于灯光烘焙的专场演讲中，演讲者通过将细小物体设置为动态物体，并添加简单的Light Probe，让渲染时间从3.5分钟下降到20秒。

OpenGL ES 图形管线
API获得顶点数据，将顶点数据从内存中拷贝至顶点缓冲区（显存）
拿到数据之后，通过attribute通道传递至顶点着色器，同时，纹理坐标通过Texture通道传递到顶点着色器和片元着色器
然后，图元装配，即图元的连接方式，一共有9种，常用的有6种，此步骤将顶点变换为图形
光栅化：确定图形与屏幕对应的位置
片元/片段/像素着色器：处理对应像素点的颜色值
在将处理好的每个像素点的颜色值存储到帧缓存区，然后在显示器中显示
API：可以通过API操作顶点缓冲区、顶点着色器、纹理坐标、片段着色器

混合光照模式(Mixed Lighting)
Unity里每盏灯光默认的烘焙模式都是”Realtime”，这代表这些灯光仍然会照亮你的场景，Unity的realtime GI系统会处理间接光。但如果默认的烘焙模式是”Baked”，那么这些灯光将会透过Unity的烘焙GI系统处理直接光源和间接光源，产生出来的光照贴图一旦贴到场景上在执行期间是不能改变的。选择烘焙模式为”Mixed”的话，场景内的静态对象会被烘焙GI拿去做计算，然而，不像”Baked”模式，混合模式的灯光仍会继续运算即时光源到非静态对象上，这对于你想把静态环境烘成光照贴图，但同时又希望同样一盏灯能为会动的角色计算阴影很有帮助。
改变模式为Baked，当烘焙完成后，灯光就可以删除了，已经将光照贴图赋给了游戏物体，灯光的作用已经消失了。

subtractive，在这种模式下的光照对于 动态物体只显示一个灯光阴影效果（下图左立方体，右边立方体为静态，有两个阴影）。
ShaderMask，对于动态和静态物体能都能显示完整的阴影效果。
将Shadow Mask设置为Distance Shadowmask即可使物体受其他物体的阴影影响
Baked Indirect，只烘焙间接光，其余情况均为RealTime，是最高级的模式，但当场景中距离大于Quality界面中的Shadow Distance时，所有阴影都不予显示。

很多客户给我们反馈，现在使用轻量级渲染管线LWRP，最欠缺的是二个功能：
首先是目前还未支持的Shadow Mask，这在老的内置渲染管线里已经有了。我们计划在Unity 2019.3提供Shadow Mask的功能。
其次是延迟渲染Deferred Rendering，它在老的管线有，新渲染管线没有，它也会在Unity 2019.3提供。

粒子系统的使用数量过大，从而导致其内存占用过高。对此，其最有效的优化方法还是降低粒子系统的使用数量，目前仍然建议将其数量控制在600个以下。建议研发团队后续对粒子系统的数量（特别是特效中的缓存）密切关注。

MMORPG手游的Draw Call数量普遍较高，且设备性能越好，数量峰值越高。这主要有以下几方面原因：
1）研发团队普遍开始针对不同机型来制定自适应的渲染LOD策略，主要包括模型LOD和Shader LOD等。
2）除LOD外，研发团队同样会对一些渲染效果进行有针对性的设置，最常见的是阴影的处理，高端机上开启实时阴影，而低端机上则通过较为简单的阴影面片或Projector来处理。另外，水体模拟也越来越多地在项目中被使用，高端设备上开启水面反射效果，也会增加一定量的Draw Call。
但就目前数据表明，研发团队已经开始有意地对Draw Call进行控制，UWA建议Draw Call占用的P95 < 200。

粒子系统的CPU开销普遍较低，且总体使用数量峰值在2018年后大幅降低。但我们依然建议研发团队尽可能将数量峰值控制在600以下。对此，建议研发团队经常通过以下两方面来检测自己的粒子特效使用情况：
1）粒子系统（特别是技能特效）的配置文件是否过量；
2）特效中是否含有长久不用的粒子系统。

GPU Instancing
批渲染Mesh相同的那些物体，以降低DrawCall数，这些物体可以有不同的参数，比如颜色与缩放

GPU Instancing与静态批处理，动态批处理的区别
使用静态，动态批处理物体的材质的所有参数是相同的，因为使用Renderer.sharedMaterial修改参数，则所有物体都会受影响。而使用Renderer.material会生成新实例，没法进行批处理
使用GPU Instancing的同一类物体的材质对象相同，但可以在代码中通过接口设置不同的参数，但仍会被批渲染。

1.不同材质的阴影会动态合批，只要绘制阴影的 pass是相同的，因为阴影跟其他贴图等数据无关
2.目前,只有 Mesh Renderers, Trail Renderers, Line Renderers, Particle Systems和Sprite Renderers支持合批处理，而skinned Meshes，Cloth和其他类型的渲染组件不支持合批处理。
3.渲染器仅与其他相同类型的渲染器进行合批处理。
4.对于半透明的GameObject，按照从前到后的顺序绘制，Unity首先按这个顺序对GameObjects进行排序，然后尝试对它们进行批处理，但由于必须严格满足顺序，这通常意味着对于半透明的材质更少使用合批处理。
5.手动的合并GameObject是代替合批处理的好办法，比如使用Mesh.CombineMeshes，或者直接在建模时将多个网格合并成单个网格。

静态批处理
原理：在Build的时候Unity会自动地提取这些共享材质的静态模型的Vertex buffer和Index buffer。将这些模型的顶点数据变换到世界空间下，存储在新构建的大Vertex buffer和Index buffer中。并且记录每一个子模型的Index buffer数据在构建的大Index buffer中的起始及结束位置。绘制的时候一次行提交合并模型的顶点数据，根据每个的，模型的可见性，调用多次DC，但是只改变一次渲染状态，之前的DC命令在Command Buffer缓存中
优点：减少CPU压力和时间
缺点：包体变大，内存变大；


动态批处理：
原理：在进行场景绘制之前将所有的共享同一材质的模型的顶点信息变换到世界空间中，然后通过一次Draw call绘制多个模型，达到合批的目的。模型顶点变换的操作是由CPU完成的，所以这会带来一些CPU的性能消耗。并且计算的模型顶点数量不宜太多，否则CPU串行计算耗费的时间太长会造成场景渲染卡顿，所以Dynamic batching只能处理一些小模型。
限制：1.材质相同
2.最高支持900个顶点属性，也就是最大300个顶点；
3.多Pass的shader会中断批处理。
4.在unity5后，动态批处理对于模型缩放的限制已经不存在了。
5.使用光照纹理的物体需要小心处理。为了让这些物体可以被动态批处理，需要保证它们指向光照纹理中的同一位置

然后xLua本身也提供了删除引用的处理LuaEnv.Tick()函数（慢慢遍历检测，引用的C#对象是否销毁，已销毁了就置null，可以解引用，后面GC就会被GC掉）调用了，且提高每次遍历的数目。

C#栈可以通过StackTraceUtility.ExtractStackTrace()拿到；
Lua栈可以通过DoString(“return debug.traceback()”)拿到；
可以把这两个字符串和obj一起记录在ObjectPool里，这样只要知道是哪个obj泄露了，也就顺便知道是哪里引入的了。

Q：想对UGUI渲染优化，发现这个问题。例如一个界面的Scrollview有很多Item，发现当UI根节点的Z为0时，会合批处理。当Z不为0的时候，Item会一个一个地绘制出来，没有合批处理。求大佬给萌新科普一下，遇见这种情形应该怎么处理比较好？谢谢啦！
A：“UI元素Position的Z值不为0时，会被视为3D UI，不参与合批。父节点Z != 0，则下面的元素都无法合批了。”


最近手上的游戏2D序列帧用得比较多， 此时使用ETC2和PVRTC因为压缩的原因，会产生闪的问题。使用拆Alpha通道的方式可以一定程度上避免，特别是对于带Alpha通道的图，ETC2质量低的原因大半在于对Alpha的压缩。
ASTC的质量是明显好于PVRTC的，iPhone上唯一的问题是iPhone 5s的支持。我们的方案是，如果机型不支持ASTC，会额外准备一份低质量的PVRTC的资源，尺寸是原图的一半，而设计的主要目的是解决内存问题，顺带解决iPhone 5s的压缩问题。
如果GameObject销毁了，但其Component仍然在不断存在，且不断上升，很有可能是你的的Lua导致了泄露。
通过Inspector里面的Show Generated Code按钮查看编译后的代码
Q：游戏在其他手机上都正常，但是在小米MIX 2上面默认右边有黑条，需要在手机上开启全面屏设置，但是有一些游戏我没有手动设置也是正确的。请问这个如何默认开启全面屏设置？

A：在AndroidManifest.xml声明max_aspect值
由于全面屏手机的高宽比比之前大，如果不适配的话，Android默认为最大的宽高比是1.86，小于全面屏手机的宽高比，因此，在全面屏手机上打开部分App时，上下就会留有空间，显示为黑条。这样非常影响视觉体验，另外全面屏提供的额外空间也没有得以利用，因此，这样的应用需要做相关适配。
针对此问题，Android官方提供了适配方案，即提高App所支持的最大屏幕纵横比，实现起来也比较简单，在AndroidManifest.xml中做如下配置即可：
< meta-data android:name=“android.max_aspect” android:value=“ratio_float”/ >
其中ratio_float为浮点数，官方建议为2.1或更大，因为18.5:9=2.055555555……，如果日后出现纵横比更大的手机，此值将需要设为更大。
因此，建议开发者在自己App AndroidManifest的Application标签下面增加下面一段代码：
< meta-data android:name=“android.max_aspect” android:value=“2.1” / >

Unity很多内置继承自UnityEngine.Object的对象如Texture、Component等，有C#和C++ 两部分内容。
以Texture为例，C#这边就是一个Wrapper，真正的纹理数据在C++ 那边。当主动执行Resources.Unlaod之后，C++ 部分被销毁，但是C#部分由于被static容器引用没有得到释放，就会造成泄露。
查询泄露简单的办法就是在ObjectTranslator中找到相关容器进行遍历，如果发现：
if(obj == null && (obj as System.Object != null))
那么就可以认为C++层已经被销毁，但是C#还在残留，也就是泄露了。原理参考：UnityEngine.Object里的迷之null（http://qiankanglai.me/2016/10/21/fake-null/）。

CommandBuffer作用就是在相机渲染的某个阶段，再另外执行自己的额外渲染，至于渲染的结果就看我们怎么用了。

在设备上Shader的加载其实并不慢，通常慢在编译上，也就是Warmup做的事情。因为不同设备GPU以及驱动不一样，因此手游上的Shader是没办法在打包的时候编译的，这就需要到设备上进行编译。（说到这个，我其实也不是很清楚在打包过程中观察到的Shader编译是在干嘛。大约是把Unity自己的Shader格式转换成目标平台的Shader格式，比如：GLSL等，这也的确是一种编译。）ShaderVariantCollection要能够有针对性地提预热（提前编译）Shader，自然是要在打包的时候根据需求收集可能用到的变体，这就和打包有了关系。至于编译，就像前面所说，打包时需要转换，到设备上才真正编译Shader。

动画从FBX中切成独立的.anim文件后，这是一个从只读动画变成可读写动画的过程。
独立的动画文件和最终发布的动画文件数据格式是不一样的，Unity会在打包的时候进行转换。在编辑器中运行游戏，如果使用的是FBX中的动画文件，Unity是直接加载最终发布形态的动画序列化数据，这些数据是在FBX导入到工程中就生成好了的，所以很快。如果使用的是独立的.anim文件，Unity加载的是这个动画源文件，需要进行数据格式转换，而文本格式的序列化文件进行反序列化时，也是极慢的，加上在Animation编辑器编辑并保存动画后，Unity还会插入原有数据量的3倍到这个动画文件中去，这也极大地拖慢了动画文件的加载速度。


项目用Xlua，发现一个问题：
一个UI（多些文字就容易复现）打开、销毁、再打开、再销毁…，如此多次，Mono会不停的增长，C# GC也不能完全GC掉。
然后发现一个会降下来的现象：
Lua GC一下，C#再GC Mono会降回去一点（但也回不到最初）。这个问题应该是两者都用了引用计数来回收， 两者不同步， 虽然Destory了对象，Lua里还没GC到，则一些被Lua引用的对象等也还在引用着。
然后两边来回GC几次，基本可以回到原来的Mono值。
网上看到类似问题，是ToLua的：
http://www.manew.com/forum.php?mod=viewthread&tid=141722&extra=page%3D&page=1

里面提了几个方案。做了2个调整：
（1）尝试Lua GC频率稍微调高些；
（2）然后XLua本身也提供了删除引用的处理LuaEnv.Tick()函数（慢慢遍历检测引用的C#对象是否销毁，已销毁了就置null，可以解引用，后面GC就会被GC掉）调用了，且提高每次遍历的数目。
但还是有增长的情况，不知大家如何解决这类问题的？谢谢！（UI做缓存池会好一些吧？但还是有一定概率会出问题，撑大Mono的）
PS：还有一点觉得难受，Lua和C#里泄漏的东西，很难知道到底当时是什么地方造成泄漏的。必须短时间内重复一些简单操作，才能推测大概泄漏的是什么东西，然后去对应地方找问题。
有什么可以方便定位哪个Lua的地方应用了哪个C#的地方？或者 C#引用了Lua的哪个地方？
比如有一些双向引用了，GC不掉，只能推测大概是哪里和哪里引用了。
A：题主对Lua和C#内存这块理解已经非常深刻了，我们也有类似问题，我们只做了第一个处理：
调整Lua GC的两个参数，让Lua垃圾回收更加积极，这个问题的原因是Lua这一端无法感知一个小小的UserData代表的东西在C#世界的分量，根基都错了只能无脑加快频率，这是最简单有效的办法了，参数合理代价也并不大。
关于撑大Mono的问题，我们应该也有，还没细抠这一块。目前正常操作，Mono峰值20几兆，就先没有管。
关于Lua引用C#，Lua这边只是拿一个索引，真正的对对象的持有是通过ObjectPool来实现的，接下来针对ObjectPool做手脚即可，分两步：
（1）记录调用栈
C#栈可以通过StackTraceUtility.ExtractStackTrace()拿到；
Lua栈可以通过DoString(“return debug.traceback()”)拿到；
可以把这两个字符串和obj一起记录在ObjectPool里，这样只要知道是哪个obj泄露了，也就顺便知道是哪里引入的了。
（2）记录分配号
为了查哪个obj泄露了，可以在obj入池的时候给它一个分配号，这个分配号自增，然后我们就可以打点diff了。
比如在某一刻打点A，此时的分配号是100，在另一刻打点B，此时的分配号是150，然后一顿各种GC释放，遍历池子找出100到150之间的obj，重点分析这一部分obj的存活是否符合预期，不符合预期的把两个栈打印出来即可。
关于C#引用Lua，这块似乎并不是重灾区，我们封装了LuaBehaviour对外使用，销毁的时候控制好，另外还有delegate也做好控制，其它的暂时没有想到。

https://mp.weixin.qq.com/s/5MH6_M3sC3RvoLal500Lqw

shader
ShaderVariantCollection https://www.cnblogs.com/wbaoqing/p/9680337.html
1.把Shader放到在ProjectSetting->Graphics->Always Include Shaders列表里,Unity就会编译所有的组合变种。
2.把Shader放到Resources文件夹下,也会正确处理,我猜也应该是全部keyword组合都编译,有知道的同学,麻烦留言告诉我。


A2：现在tx新上线的项目已经开始普及ASTC的使用了，所以全面选择ASTC，2019可以默认import的时候选择ASTC，尤其是对光照贴图和法线有很好的效果。Unity现在默认是6x6，也可以根据项目选择其它大小。
模拟器虽然是opengles3，但是可能不支持astc etc2，硬件支持软件，虽然不支持astc etc2，但是可以运行指示帧数比较低。

1）使用Tiled模式的Image组件：Tiled模式的Image组件可能产生过多的面片，建议进一步检查。
2）精度过高的动画片段：建议把精度缩减到3－4位，从而降低动画片段的内存占用。
3）未使用PCM格式的音频：未使用PCM格式的音频可能存在音质问题，建议进一步检查。
4）Wrap模式为Repeat的纹理：Wrapmode使用了Repeat模式，容易导致贴图边缘出现杂色，建议进行检查。
https://mp.weixin.qq.com/s/UkuxNLEP3_oHp95NbleONg

视域剔除在默认渲染管线中是一定会做的，但它剔除的基本并不是以Triangle为单位，而是以GameObject为单位的，只要这个GameObject（Mesh）的包围盒与视域体有交集，就会被认为是要渲染的，所以会将其Triangle全部放入Draw Call中，并传入GPU进行渲染。因此，你会看到Statistics中显示的三角面片是很高的。
在传入到GPU后，该Draw Call中所有的顶点都会进入Vertex Shader阶段，所以如果该Mesh是8000个Triangle，那么这8000个都要进行计算，从目前我们所优化过的游戏项目（特别是重度MMO）中可以发现，很多时候都是几万的网格顶点在这里进行计算，在中低端设备上都会造成不小的计算量。
而你问题中说的光栅化实际上是在Vertex Shader之后，也就是要到Fragment Shader阶段，这个时候是在经过一系列操作（比如深度检测等）后将Triangle向屏幕进行投射，然后通过光栅化进行颜色计算，再经过各种Buffer之后形成最终的FrameBuffer，也就是我们最终看到的内容。
渲染Pipeline大体上是上述过程，所以通过上面的说明，题主就可以明白，光栅化和视域剔除其实没有关系，前者是GPU部分，后者是CPU部分，功能是完全不一样的。光栅化主要根据每个Triangle在屏幕上的投影来计算颜色，跟Mesh中Triangle的前期剔除是没有关系的。Statistic中的统计没有问题，因为确实有一定数量的Triangle被传入到了GPU中。如果你的项目遇到了这种情况，那么我建议将其切成小块来进行渲染，因为从概率上来说，它可以降低渲染计算压力。希望上面的说明能对你的疑惑有所帮助。

Q：请问AssetBundle.LoadAssetAsync()这个真的是异步获取资源吗？我用的是个人版Unity，这个API会阻塞主线程，是不是需要专业版才行呢？

A：AssetBundle.LoadAssetAsync()在加载资源的时候，比如Prefab，它里面用到的各种Texture、Mesh以及Shader都会在子线程Worker线程中进行加载。但是加载完成后会有后处理，比如Shader.Parse是一定会在主线程处理的，Texture和Mesh需要上传到GPU。如果开了多线程渲染并使用AUP功能，非RW的Texture和Mesh的上传会在渲染线程处理；如果没开多线程渲染，那么这一部分还是会由主线程来完成。这些后处理的名字叫XXX.AwakeFromLoad，如Texture.AwakeFromLoad，当主线程触发这些回调的时候，主线程其它的Update操作就必须等这些后处理完成才能继续。

还有其它的像Prefab的序列化，各种Component的序列化等也都是在主线程完成的。所以一次AssetBundle.LoadAssetAsync操作，其实并不是完全的异步，主线程中依然是要做不少工作。具体细节可以观看UWA DAY 2019年的视频，里面的讲解非常清晰：https://edu.uwa4d.com/course-intro/1/91
https://mp.weixin.qq.com/s/LUlZ-VvjxOghMDD9X4cKZg

渲染视域剔除
